

# 分布式
## zk
1. 配置，注册，协调，命名服务
2. CAP，P保证，C&A取舍，zk->CP保证所有数据同步一致
3. 维护元数据+ 监听变动
4. ZNode -> 临时（session）-> instanceID，持久，顺序编号，临时自动
5. 发布/订阅， zk register<-> notify client -> watchermanager callback
6. ACL 权限控制
7. write req -> follower -> leader -> zab-> all followers (内存同步+磁盘更新)，read -> 无所谓
8. zab -> zookeeper atomic broadcast 原子广播协议； write -> leader -> 协议to follower -> 半数同意->commit;
    选举+ 恢复（同步与LD的数据）， 类似2pc
9. 选举 -> 都可以投自己 -> 收到别人的投票 -> 比较的是事务id
10. 配置奇数台 n/2 -> 5的时候 可以挂2，6的时候也是2
11. sessiontimeout 这个时间重连session还是有效

## id gen
1. UUID -> 太长，不容易存储；但是没有网络消耗，mysql主键越短越好。
2. 雪花算法： 高位 + 时间戳 + 集器标识 + 序列号 -> 时钟回拨
3. DB-> 强依赖DB -> 主从切换 可能导致重复
4. bizID+号段+step -> leaf 可以线性扩展 -> 双buff

## 分布式事务
1. 2PC -> 二阶段提交 -> 事务管理器 -> 协调多个数据库 问问 多个db准备好了麽 -> 提交
2. TCC: Try Confirm Cancel .Try：锁定/预留;Confirm: 执行实际操作； Cancel阶段:补偿+ 回滚 -> 跟支付相关的会用TCC。严格的场景采用这种方式。
3. 本地消息表 -> 用的也很少。
4. RocketMQ 
## 分布式token
1. JWT token
2. Redis.


# Java
## base - 集合
1. hashMap 转红黑树 -> 数组长度64+ 链表长度8
2. arraylist
```
1. cap=10,扩1.5， 
2. Collections.synchronizedList();
3. CopyOnWriteArrayList();
```

3. concurrentHashMap
```
1. 计算数组下标
2. null ? cas 操作 -> next -> sync(node) -> 尾插 -> if 红黑树 插入新结点 -> 转换红黑树（8/64）
``` 

4. linkedlist
```java
1. 双向链表 -> 不安全-> Collection.sync
2. pre, next, value
3. 
```

# Jvm
## 内存
1. 程序计数器- >字节码行号 循环跳转 线程恢复 线程私有 非oom
2. 虚拟机栈 -> 线程私有 -> 栈帧 方法入栈出栈 局部变量，对象引用，stackoverflow,oom，数据类型int/long -> return/exception
3. 本地方法栈 native
4. 堆 -> 对象分配/大数组 ->GC-> 新生代/老年代 eden from/to -> 15age/大于一半/大对象
5. 方法区 -> meta space -> 直接内存 -> MetaSpaceSize ->不受jvm内存限制/空间可以调整
6. 运行时常量池 -> heap(之前再方法区) -> 类信息，字段，方法，常量池/final -> oom 
7. 直接内存 -> NIO DirectByteBuffer -> 避免在Java heap和内存来回复制数据
## 对象
1. 类加载检查
2. 内存分配 -> 类加载确定 -> 指针碰撞(没有碎片)/空闲列表（cms） -> CAS失败重试/TLAB/
3. 初始化零值 -> 基本类型的赋值
4. 设置对象头 -> hash,分代，偏向锁，类信息
5. init
对象头，实例数据，对齐填充


## GC
1. 优先eden,大对象直接老年代，长期存活的对象老年代，相同年龄大于一半，超过的直接老年代
2. 引用计数法，GCRoot -> 栈中对象，静态引用，常量池
3. 强，软（内存不够才会回收），弱（发现就回收），虚
4. 二次判断，finalize是否已经执行过，执行过的就回收，没有就进行二次标记
5. 无用的类 -> a. 所有实例 b. class 不能通过反射 c. 加载该类的classloader被回收
6. 标记清除 —> 碎片+ 效率/ 复制-> 浪费空间/ 标记整理
6. 新生代-> 死亡对象多 -> 复制算法/ 老年代 —> 标记清除/标记整理
7. Serial, stw, 简单高效，串行，client模式不错选择
8. ParNew -> Serial多线程版本,新生代复制，老年代标记整理 -> 可以与CMS配合使用
9. Parallel Scavenge 提高吞吐量 -> 关注用户停顿时间->新：复制；老：标记整理
10. CMS -> ConcurrentMarkSweep标记清除—> 并发标记,低停顿 ->
```java
1. 初始标记 -> 暂停所有线程 -> 记录与gcroot相连对象
2. 并发标记 —> 重新标记(修正并发标记期间程序继续运行导致标记变动的那个) -> 并发清除 
3. 缺点:对CPU资源敏感,无法处理浮动垃圾，标记-清除算法 会有碎片
4. 浮动垃圾：并发标记期间用户取消了引用，重新标记不能get到。
```
11. G1 -> 初始标记，并发标记，最终标记，筛选回收 -> 维护优先列表-> 根据收集时间优先厕价值最大的region.

## 类加载
1. .class 文件二进制加载到内存中，放在运行时方法区内(运行时常量池)，在heap创建一个java.lang.class 对象，用来封装类在方法区的数据结构。
2. 加载 连接 初始化 使用 卸载
3. 连接 -> 验证：文件格式，元数据，字节码 准备：为静态变量分配内存，初始化 解析： 将符合引用转为直接引用
4. 初始化：为类的静态变量赋予正确的值
5. bootstrap class loader,extendClassLoader,appClassloader -> 全面负责，父类加载-自己尽量不处理交给父类处理 -> 缓存机制—> 修改之后重启
6. 加载 验证 解析 初始化 使用 卸载 

## 并发
1. AQS -> Lock,Semaphore,ReentrantLock 等等，原子式管理state,block & queue
2. Reetrantlock, 公平，非公平，可重入，可中断
3. state -> CAS 同步状态是否成功-> 成功则独占线程-> 失败则acquire
4. 请求的共享资源空闲 ->设置有效工作线程，资源锁定，如果资源被占用，则进入队列等待唤醒。
5. volatile -> state(cas) -> Node (thread, waitstatus,prev,next,predecessor) -> shared/exclusive
6. thread local -> thread 私有的Map -> weak Reference 
7. CorePoolSize,MaxPoolSize,KeepAliveTime,Unit,WorkQueue,ThreadFactory,Handler
8. sync -> 同步语句块（带对象这种）monitorenter/exist/monitory
   同步方法 -> ACC_SYNCHRONIZED

## NIO
1. Channels -> Connections to files,Sockets which support non-blocking read 
2. buffers -> byte array can be read&write by channel
3. selectors -> channel -> has event
4. Reactor 线程模型 -> client/ dispatch thread/ acceptor/ read - decode -compute - encode -send
5. client -> mainReactor -> acceptor -> subReactor -> thread pool(read/compute/write)
6. bio,n-bio,io 复用/异步io
7. bio accetpt监听连接，阻塞等待新连接到来，来了才能继续工作， -> 读写io阻塞，占用系统资源。来一个请求开一个thread.
8. nio可以用一个线程把accept，读写操作通过event全做了。
9. .select -> 文件描述符有1024的限制，还要copy到内核-> 还不能能复用，还要轮询看看哪个好了
  epoll -> 共享内存fd,事件好了告知进程一个名单去处理，更方便。
10. 边缘 内核缓冲区由空转非空的时候发出可读通知。由满转成不满的时候，发出可写通知。效率更高，netty采用
    水平：只要非空，就一直信号通知。JDK NIO使用。


## MQ
1. 有序 -> 发送端/消费端 相同的  partition -> msg key
2. producer存在两个线程，producer主线程，send之后立即返回，不关注是否成功.
3. 幂等性 -> insert 做唯一键/set天然性  
4. 异步写缓存，系统解耦,流量削峰,换冲通信,消息顺序性以及回溯
5. 持久化 + 多副本 分布式 可用性高
6. 分区中所有的副本称作 AR(Assigned Replicas),但是其中有部分副本与leader保持一定程度的同步,称作ISR(In-Sync-Replicas)
7. Leader副本负责管理所有ISR副本滞后状态（超过10s踢出）,滞后太多的就把他剔除，当leader副本发生故障的时候，只有isr中副本才有资格选举成为新的leader。
8. HW:High Watermark, LSO：Log Start Offset, LEO -> Log End Offset,ISR中最小的LEO就是HW,LW 低水位 -> AR中最小的LSO -> 拉取可能会导致旧的被清理导致 LW增加
9. 分区策略 -> 轮询，hash,随机
10. 序列化器-> 生产者把对象转换成byte数组 发送给Kafka；分区器-> 如果没有指定partion则根据key计算partion. 拦截器->序列化器->分区器
11. producer有两个线程，主线程把消息序列化，拦截器 放入到 消息累加器中，然后sender线程在里面取出数据进行发送。
12. 旧版本Kafka 依赖zk,之前将offset写入到zk，但是zk不适合频繁写更新，consumer的offset更新是非常频繁的，这样拖累zk
13.  重复消费 -> rebalance -> 加入新的consumer -> 导致一条消息还没消费完成就被别的消费者领走了。
     手动提交 -> 先消费消息 再提交offset，导致重复消费/ 重启 临界/ 生产者重发
14. 消息消费失败： 自动提交但是内存崩了；
15. segment Kafka最小存储单元,把partion进行分割，方便查找和删除。index索引文件 + log数据存储文件 组成
16. rebalance -> a. group 中consumer 断开 b. partion 增加 c. 在同一个集群中，订阅的topic增加，使用相同的groupname;消费者每次重启的时候都会rebalance; -> 会导致所有的消费停止。
17. 理想情况下，consumergroup的consumer数量和 partion一致。
18. 写数据的时候leader持久化本地 -> flower来leader 拉去数据，一旦 follower同步好了，ack给leader -> ack给producer.
19. 顺序 -> partion -> 对应一个consumer  -> 相同key分配到同一个内存队列，（多队列） -> 多线程处理
20. 消息挤压  -> 临时分发到新的topic partion多一些,紧急修复consumer. -> 手动补发。
## rocketmq
1. 事务
```
1. halfmessage
2. halfmessage send ok
3. local transcation    
            -> success -> commit
            -> failer  -> rollback
    
    or mq check when not response -> checklocal -> commit or rollback

4. commit or rollback
```

## Net
1. Https 利用非对称加密进行身份认证和密钥协商，利用对称加密进行数据加密，利用散列函数验证信息的完整性。443
2. 三次握手 确保双方的发送接收正常. seq = x,ack = x+1,seq = yt,ack = y+1
3. 半连接队列 -> server 第一次收到 syn_rcvd，双方没有完全建立连接，这种状态下放到请求队列中，这种成为半连接队列。server 发送完 syn-ack，如果没有等到客户端的回复，则进行重传，超过就在半连接删除-> init number不是固定的 ，随着时间变化。
4. 第三次握手可以携带数据，前两次不可以，防止攻击。
5. syn攻击 -> client 短时间向server发送不存在的ip,server 需要ack一直确认，浪费流量 -> dos攻击
-> 缩短超时时间,增加最大半连接树/网关防护/单ip限制
6. 四次挥手 -> c -》s我想要断开，close wait -> server ok. -> server 我想断开 -> c ok -> 2msl断开 -> 这个期间这个ip+port不能用 -> 防止client对于server的ack丢失。
7. TCP可靠性 -> 校验和/序列号/确认应答/重发控制/窗口控制
8. 应用层（http/dns）-> 传输层（tcp/udp）-> 网络层 (IP，ICMP上层传递的报文段封装)-> 数据链路层（封装成帧） -> 物理层 
9. 数据链路层 a. 封装成帧（帧首部+IP数据报+帧尾部,最大1500字节）b. 差错检验

## Netty
1. netty是main/sub Reactor 是在NIO的基础上更高层次的抽象。Accept单独的线程池处理，读写操作也是单独线程池。
2. API简单，断线重连，粘包和半包 -> 我们发送的bytebuff，但是底层按照字节流发送数据，到了服务端，重新拼装bytebuff,但是协议是不对等的，我们需要自定义协议 -> 按照协议来组装数据包
3. 没有netty，每次都需要判断是否是一个完整的包-> netty其实就是帮我们实现了一些。
4. zero copy -> 传统 磁盘-> 内核buffer -> 用户缓冲区 -> 内核socketbuffer ->网卡接口缓冲区
    zero 是： DMA -> 内核read bufer -> 网卡接口buffer
5. netty 中zero copy
    a. bytebuffer ->  DirectMemory直接进行socket的读写-> 避免cp到heap
    b. composite buffers -> 组合buf，减少内存的copy

## Redis
1. Redlock -> 解决master结点down,还没同步到slave的情况。向过半结点发送 setnx +ex指令,过半成功则加锁成功—> 性能较低+ 复杂 ->在乎高可用可以用
2. 过期 -> 独立字典-> 定时遍历+惰性删除 -> 过期扫描 20key并且删除这里面过期的-> 如果超过1/4则继续，所以不要同时过期-> 会导致很慢 -> 从库的过期都是来自主库的del命令
3. 实际内存超出 maxmemory -> a. 不写了（del除外）b. 淘汰lru过期key c. 随机淘汰 d. all lru f. all-ttl
4. SDS->Simple Dynamic String-> byte数组+长度信息-> 小优化点：长度都用byte/short表示了-> 不超过512M -> 还有lru -> 小于1M 加倍扩容，超过1M每次扩容1M
5. setnx + ex
6. 用keys会阻塞，可以用scan ->自己去重
7. list队列 -> rpush生产消息 -> blpop消费消息 / redis实现延迟队列 用score，zset -> zrange 取出数据。
8. pub/sub -> 消费者下线情况下，消息会丢失。
9. fork + cow 父子进程共享数据段，父进程继续提供写的服务。
10. pipline 将多次IO网络交互整理成一次，减少网络消耗
11. 雪崩 -> 同时失效 -> 加随机值 ； 缓存穿透 bloom filter-> 不存在的key ； 缓存击穿 -> 热点key突然失效 -> 穿透 
12. 纯内存 + 单线程减少上下文竞争 + IO多路复用模型
13. 哨兵 -> 集群监控/消息通知/故障转移/配置中心


## mysql
1. master -> binlog slave -> Io thread read from master to local relay log, sql thread read and reply it.
2. 主从延迟 -> master TPS高，并发产生修改操作，而slave 结点的sql是单线程处理数据，所以有延迟。/网络/大事务/单线程复制 5.6开始支持多线程/并行复制/分库 -> 每个一套salve压力就不大了。
3. 分库分表 -> 冷热数据分离 热数据 （近3个月）；半年的冷数据，1年的冷数据；
   mysql + es + hive 分别存储这三类的数据。
4. 数据迁移 -> 主动脚本 + 被动 业务双写+ 版本号 + redis缓存状态 + localcache 配置开关 + 记录状态迁移状态。
5. 连接层 socket连接/授权认证/SSL-> server服务层(mangment/sql interface/Parser/优化器/缓存)
6. ACID (Atomicm,Consistnecy,Islation,Durabllity);Read Uncommitted, Read Commited,Repetable Read,Serializable
7. 脏读，不可重复读 -> 读到了别人修改的内容 ; 幻读 -> 同样的条件，读取到了不同的记录，这里面有insert/delete
8. 加锁 + MVCC 创建版本号+ 删除版本号；MVCC解决的是不可重复读的问题，间隙锁解决的是幻读的问题。
9. 事务的隔离性通过 锁机制实现，持久性通过 redolog,原子性和一致性 undolog.undolog在执行操作之前备份到一个地方，出现错误或者rollback，回复undolog.redolog是 记录最新数据，持久化。
10. 检索快；主键索引/非主键索引 -> 更新的时候需要更新索引文件
11. 使用短索引（节省磁盘IO），区分度高，联合索引，查询的列+ 排序的列使用索引;like%走索引，
12. 自增主键 ：存储空间少，性能最好，减少页分裂。页分裂 -> 数据页之间通过双向链表 ->每个数据页大小有规律，不满足就会分裂。我们存储主键后面一个数据页要大于前面一个数据页，方便二分。如果索引无序，那需要经常性的挪动。
13. 主键不重复不为空，唯一不重复可为空，主索引性能高与唯一索引。
14. 回表查询 -> 先查询普通索引树 -> 根据主键id 去主键索引进行查询。覆盖索引，abc;select a,b,c where a = 1 and b =2;遇到范围 > < like 都会中断索引
15. force index为什么没有使用？ -> 不在候选索引中。
16. or会使mysql放弃索引，改成全表扫描。
17. 意向锁，读共享，写互斥（T2不能读写）；next-keys locks = 行锁 + 间隙锁 ； 快照读/当前读
18. 先再非聚簇索引加锁，在从聚簇索引加锁。
19. 

## TIDB
1. 扩展性 分布式数据库，我们不用做分库分表了
2. 支持sql，在语法上与mysql没有任何区别,支持ACID.
3. TIDBserver 负责链接client, 执行sql解析和优化 -> 生成分布式执行计划,无状态，可以扩展
4. PD Placement Driver-> 维护集群元信息，负责整个拓扑结构
5. TIKV -> 负责存储数据。 负责几个region。每隔region是一个组Key Range 范围数据,本地存储使用的RockesDB,KV持久化map.
6. 分布式  -> 副本 -> Raft协议
7. KV空间分成很多段 -> 每一段是连续的key，每个region 保存的数据不超过一定大小。
8. 他也有MVCC -> 是通过在key后面添加版号控制。
9. Key : TabelID + RowID ;Value:[c1,c2,c3]； Key = tableId+indexId;t10_r1 --> ["TiDB", "SQL Layer", 10]
10. 遍历扫描下沉到存储结点 之后聚合，避免无意义的网络传输。
## 秒杀系统
https://juejin.cn/post/6844903999083151374
1. 时间短/瞬间用户量大
2. 考虑 缓存雪崩/缓存击穿(bloomfilter)/缓存穿透/超卖问题/恶意请求/限流/降级/熔断
3. 分布式部署+单一职责（避免拖累其他系统）
4. URL动态化，避免链接提前暴露 -> MD5+随机码
5. Redis集群+ 主从同步+读写分离
6. ng负载均衡
7. 恶意请求拦截 -> 避免把带宽打满
8. 资源静态化 -> CDN+ FE 服务器
9. 按钮变灰控制 -> 前端限流 + 后端限流
10. Redis分桶 避免热点key，加队列
11. 限流 降级，熔断，隔离
总结： 按钮灰 -> CDN静态 —> ng(过滤) -> server集群-> local/redis集群lua扣库存DECRBY -> rocketmq队列下单 -> 生成订单 -> 持久化mysql -> 消息通知

## bloom filter
1. 几个hash 散列函数 -> byte数组上 -> 每当一个元素到来的时候 hash判断位置是否有值，有值可能在集合中，没有一定不在。 -> 大量item变动 -> 我要判断吧是不是在我的DB中。
2. 缺点 -> 不能delete -> 需要定时重建 来维护数据的准确性 

## ES
1. 深度分页  -> 在5个主分片索引中进行搜索，当我们请求我们分页在10001 -10010的时候，需要每个分片 前10010结果，然后再排序，产生 10个，这样浪费资源，在分布式系统中，排序结果的花费随着分页的深入而成倍。
2. text分词 -> 倒排索引 不用于排序，很少用于聚合; keyword -> 适用结构化字段，需要进行过滤，排序，聚合，精确搜索到。
3. term 精确匹配 ， terms 多个条件, bool查询。
4. 深分页优化 -> 返回id+score + fetch 拉去 100 -110的数据 -> 限制分页（只能看前100页）
    a. scroll 游标 -> 适合后台批处理任务，比如群发 -> 一次性查询大量数据 ->在初始化的时候将所有符合条件的doc_id缓存 -> 遍历的时候从快照取数据。
    b. 优化方式： scroll scan  -> 不支持排序,不用排序取数性能提升 -> 
    c. serch after -> 都是采用游标的方式。
5. 倒排索引 keyword1 出现在了哪些文档doc_id中。可能是链表或者B+树/频次。Helloworld	(2:1),(1:1)/ termIndex (字典树) -> term dictionary -> position ； 公共前缀崔在一起。
6. 准实时 -> ES写入数据会先写入到内存buf中，每隔1s刷新到os cache ，这时候就能被搜到，所以准实时。-> 调用refresh直接刷入os cache 。5s之后会刷到磁盘，所以可能存在 5s数据丢失。
总结： 数据 -> es内存buff -> 每隔1s os 内存buf （能搜到） -> 5s translog文件（崩溃恢复） -> 30s/阈值磁盘文件。
7. doc -> field 相当于一条记录； index -> DB， type-> table; document -> record
8. shard master(primary)+ replica ，master的主从切换。
9. 写数据 -> 协调节点 -> 路由到node -> primary node 处理 -> 同步到 replicanode -> 响应client
10. 读数据 -> 任意node -> hash -> primary/replica 随机一个，读负载均衡。
11. 检索 -> 任意node协调节点 -> 转发到所有shard -> 搜索结果doc_id,socre -> 协调节点 聚合排序-> 拉取doc实际数据。
12. .del 和定期segment file 的merge.
13. 怎么搜索更快 -> filesystem cache -> 还是要增加机器内存 + 只缓存索引搜索项，避免占用内存.+ 数据预热。+ 冷热数据分离,不要在一个素银中。


## 项目
面试官你好，我叫侯振国，2016年毕业于烟台大学。从2015年从事开发已经快7年的时间了。主要从事的Java开发，Golang开发。上一家公司是shopee Marketplace Item组，
主要负责的是 商品分类相关系统的开发，包括 item-label/ item-tag / SPU（标准产品单元）/前台类目/商品评论等系统的开发。这些系统主要用于商品的精细化分类，方便
推荐和搜索使用，以及数据分析。主要采用的技术是 Golang,Redis Cloud,Kafka,Gorm,Mysql,TiDB. 本人对Java开发Golang开发比较熟悉. 这些系统的目的主要是给商品提供分类以及对上游订单，促销 逻辑影响。
之前在快手 运营研发部门 做 璇玑系统，主要负责的是 用户管理，数据分析看板，标签，垂类，政务媒体号，以及用户认证，主要用到的技术是 java ,druid,es,kafka等等。

1. ProductLabel 
PDP Page -> Wsa网关 
dataProvider -> 提供item/label数据查询; 主要是系统的解耦。有查询类的server， 写入类的server, task类的server。主要用于 搜索：比如 shipbyshopee/是否是海外/物流支持哪些
这些都是标签，比如我们购物的时候角标会有 多少折，以及其他的角标 这些都以tag/label的形式进行存储,用户下单的时候的赠品，绑定。以及qc审核流程的违禁品或者某些其他特殊品类的商品都是采用这种方式进行存储。
主要服务包括 apis 主要对外提供写服务，dataprovider提供读服务。大概有 50个proxy+ 200 master + 200slave个 + Total 3.13TB 使用 40% 数据量在3k*50 = 15w左右
product-tag -> 通过 binlog更新缓存+ 缓存。

Item-Tag: background 提供给search等偏离线的系统使用, tag 主要对外提供服务，是通过部署不同的SDU,提供给不同的业务方进行使用。进行流量的隔离。我们的部署都是按照region。
TagTaskConsumer -> quick,common,slow.使用不同的topic和不同数量的consumer -> 调用item info的接口。 
同时我们的TIDB会发出 binlog -> 下游的各个系统监听binlog ,进行 反向索引的更新，item-tag event 的发布，item tag-cache的更新。

## 堆排序
1. 完全二叉树 -> 从最底层的最左边的节点
2. 父节点 > 子节点 
3. 从倒数第二层开始hepfiy
4. 从顶往下编号， i的parent = （i-1）/2； i的c1 = 2i+1, c2 = 2i+2


## 堆排序 https://www.bilibili.com/video/av47196993?t=1250

https://www.runoob.com/w3cnote/heap-sort.html

```c
void swap(int arr[], int i, int j) {
    int temp = arr[i];
    arr[i] = arr[j];
    arr[j] = temp;
}

// parent = (i-1)/2
// c1 = 2i+1
// c2 = 2i+2

// 对i做heapfiy(前提 子树已经堆排完)
void heapify(int tree[], int n, int i) {

    if (i >=n) {
        return;
    }
    int c1= 2 * i +1;
    int c2 = 2 *i +2;
    int max = i; // 假设i是最大值

    // 查找 三个节点中最大的
    if (c1 <n && tree[c1] > tree[max]) {
        max = c1;
    }
    if (c2<n && tree[c2] > tree[max]) {
        max = c1;
    }
    if (max != i) {
        swap(tree, max, i);
        heapfiy(tree, n, max);
    }

}

void build_heap(int tree[], int n) {
    int last_node = n -1;
    int parent = (last_node -1)/2;
    int i;
    for (i = parent; i>=0; i--) {
        heapfiy(tree, n, i);
    }
}

void heap_sort(int tree[], int n) {
    build_heap(tree, n);
    for (i = n-1;i>=0;i--) {
        swap(tree,i,0);
        heapify(tree, i, 0);// 包含砍断的过程
    }
}

int main() {
    int tree[] = {4,10,3,5,1,2};
    int n = 6;

    build_heap(tree,n)
    //heapfiy(tree, n, 0);
  // 把根节点和最后直接交换，然后砍断最后。一直heapfy(0)
}


https://zhaopin.meituan.com/web/position/detail?jobUnionId=1083663022&highlightType=social