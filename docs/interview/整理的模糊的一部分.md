本文所有的内容都是在工作之余整理。主要是自己知识区的盲点。为了来年做好准备。

# Java

1. 快速失败 (fail-fast) 和安全失败 (fail-safe) 的区别是什么？
    fail-fast :ConcurrentModificationException -> foreach remove-> 先记录一下，每次迭代判断 -> HashMap
    单线程的迭代删除，多线程的修改
    fail-safe: 对集合的修改是在copy的基础上。CopyOnWirteArrayList, ConcurrentHashMap
    fail-fast: 迭代删除 ， java8 removeIf map.keySet().removeIf();

2. HashMap
    getNode first判断 -> hash,key,value校验 -> is TreeNode ? TreeSearch : Next do while
    Node[] ; hash &(length-1) ; put new Node change val
    红黑树 logN 
    对于put操作，如果Key对应的数组元素为null，则通过CAS操作将其设置为当前值。如果Key对应的数组元素（链表表头或树的根元素）不为null，则对该元素使用synchronized关键字申请锁，然后进行操作。如果该put操作使得当前链表长度超过一定阈值，则将该链表转换为树，从而提高寻址效率

    将链表转换成红黑树前判断，如果当前数组的长度小于 64，那么会选择进行数组扩容，而不是转换为红黑树
    hashmap转红黑树的两个条件:一个是链表长度到8,一个是数组长度到64.

3. HashSet 和 TreeSet 有什么区别
   hashSet :无序
   treeSet：有序 Compartor
   LinkedHashSet是一种有序的Set集合，即其元素的存入和输出的顺序是相同的
4. Iterator 和 ListIterator 的区别是什么？
5. 序列化 与反序列化的大坑，参考我的 core/序列化与反序列化.md
6. TreeSet 底层也是 TreeMap. 通过equals去重。 HashSet 底层是 HashMap
7. 下面这条语句一共创建了多少个对象：String s="a"+"b"+"c"+"d";
```
        对于如下代码：
        String s1 = "a";
        String s2 = s1 + "b";
        String s3 = "a" + "b";
        System.out.println(s2 == "ab");
        System.out.println(s3 == "ab");
        第一条语句打印的结果为false，第二条语句打印的结果为true，这说明javac编译可以对字符串常量直接相加的表达式进行优化，不必要等到运行期再去进行加法运算处理，而是在编译时去掉其中的加号，直接将其编译成一个这些常量相连的结果。
        题目中的第一行代码被编译器在编译时优化后，相当于直接定义了一个”abcd”的字符串，所以，上面的代码应该只创建了一个String对象。写如下两行代码，
                String s ="a" + "b" +"c" + "d";
                System.out.println(s== "abcd");
        最终打印的结果应该为true。
```
8. 当try和finally里都有return时，会忽略try的return，而使用finally的return。finally没有return时候，将 try return的存储起来，然后最后return回去。
9. jvm 在编译时期将 boolean 类型的数据转换为int ，boolean 使用 byte数组实现的。

为什么不用byte或short，这样不是更节省内存空间吗。经过查阅资料发现，使用int的原因是，对于当下32位的处理器（CPU）来说，一次处理数据是32位（这里不是指的是32/64位系统，而是指CPU硬件层面），32 位 CPU 使用 4 个字节是最为节省的，哪怕你是 1 个 bit 他也是占用 4 个字节。因为 CPU 寻址系统只能 32 位 32 位地寻址，具有高效存取的特点。

10. since9 string 底层使用 byte[] 而不再是 char[], byte 1个字节，char 两个字节。

11. string final 好处？ 1. 可以使用 string pool, 2. 缓存hash值 3. 传输安全 线程安全
12. 1.1字面量为 double 类型，所以不能 直接 float a = 1.1 ，因为向下转型，会丢失精度，所以要在后面加f
13. short s1= 1;s1 =s1+1; 不行。-> s1+=1;可以，因为做了隐式的转换。
14.   a-b< 0 b>a a -b 存在溢出

15. 编译不通过 类型擦除 泛型遇上重载
```java
    public static void method(List<String> list) {  
        System.out.println("invoke method(List<String> list)");  
    }  

    public static void method(List<Integer> list) {  
        System.out.println("invoke method(List<Integer> list)");  
    }  
}  
```
16. 数据溢出的问题
17. int的自动装箱都是通过Integer.valueOf()方法来实现的，Integer的自动拆箱都是通过integer.intValue来实现的。
18. String s = "a" + "b"，编译器会进行常量折叠(因为两个都是编译期常量，编译期可知)，即变成 String s = "ab"
对于能够进行优化的(String s = "a" + 变量 等)用 StringBuilder 的 append() 方法替代，最后调用 toString() 方法 (底层就是一个 new String())
19. for 循环使用 sb,其他时候使用 + 没问题，因为底层使用 的是 StringBuilder 但是for中每次都是 StringBuilder
20. 静态代理的用途 控制真实对象的访问权限 通过代理对象控制对真实对象的使用权限。
21. 因为异常不能跨线程传播回 main() 中，因此必须在本地进行处理
22. interrupt() 与 interrupted()方法，以及 sleep
23. shutdown -> no new task 之前提交的执行完成
    shutdownnow -> interrupt方法 ->设置所有的为interrupt -> remove 队列中的 -> return -> 不保证interrupt生效
24. 通过调用一个线程的 interrupt() 来中断该线程，如果该线程处于阻塞、限期等待或者无限期等待状态，那么就会抛
    出 InterruptedException，从而提前结束该线程。但是不能中断 I/O 阻塞和 synchronized 锁阻塞。 
25. 如果只想中断 Executor 中的一个线程，可以通过使用 submit() 方法来提交一个线程，它会返回一个 Future<?> 对
    象，通过调用该对象的 cancel(true) 方法就可以中断线程 

26. blockQueue.put 阻塞， add -> throws ex offer-> return false;
27. AQS state -> CAS 成功获得锁，失败 -> 阻塞 —> volilate

28. LinkedBlockingQueue 之所以能够高效的处理并发数据，还因为其对于生产者端和消费者端分别采用了独立的锁来控制数据同步
29. SynchronousQueue ->newcachethreadpool -> 不缓存，传球手

27. StackOverflowError 和 OutOfMemoryError 都不属于 Exception 的子类
28. 方法区是规范，永久代是实现。
29. 二进制相关操作需要每日熟记 
30. return (num > 0) && ((num & (num - 1)) == 0);
31. Queue<String> q = new LinkedList<>(); q.add q.poll  stack.push

31. StringBuffer -> synchronized 保证线程安全。
32. ThreadLocal weak -> 线程池中的thread重复使用 使用强引用可能无法回收
33.  类的元数据放入 native memory, 字符串池和类的静态变量放入 java 堆中
34. String.valueof;和String = ""+1;的区别

# SQL
```sql
delete p1 from Person p1, Person p2 where p1.Email = p2.Email and p1.Id > p2.Id; --删除 重复邮件

select e1.Name from Employee e1 inner join Employee e2 on e1.Salary > e2.Salary and e1.ManagerId = e2.Id; -- 查询工资大于其经理工资的员工

# 查找每个部门薪资最高的人
select D.Name as Department,E.Name as Employee,M.Salary as Salary from 
    Department as D,
    Employee   as E,
    (select max(Salary) as Salary,DepartmentId from Employee group by DepartmentId) as M
    where E.DepartmentId = D.Id and E.Salary = M.Salary and E.DepartmentId = M.DepartmentId;

select (select DISTINCT Salary from Employee order by Salary desc limit 1,1) SecondHighestSalary; -- 查询第 二高的人，没有返回null (注意去重)

-- 做到 178 178. Rank Scores
```


# 知识点快速回顾

## 分布式

### 分布式锁
-
1. Redis -> set(lockKey, lockValue, "NX", SECONDS, 30); // NX, 过期时间，释放锁的 LUA 原子性 val:随机数+threadId
2. ZK -> `临时顺序节点` -> 返回子节点列表 -> 自己是否第一 -> 加锁 or 监听上一个 。尝试加锁 -> 挂掉 zk自动删除
3. redis 获得锁的客户端挂了，只能等待超时释放锁。zk 可以自动释放。zk 是注册监听事件。

### 分布式事务

1. CAP: Consistency Avalibility Partion Tolerance

    C: 强一致性 A: 服务一直可用 P: 挂掉一部分仍可用 

    大多数场景下：舍弃掉 C,退而求其次，最终一致性AP。钱： CA

    顺序一致性 最终一致性。

2. BASE : 基本可用，同步延迟时候允许存在中间状态 ，最终一致性。

    BASE理论的核心：就是牺牲 强一致性。

3. 二阶段提交

    precommit -> yes or no -> commit or rollback -> ack

    缺点： `协调者` 单点故障 。 二阶段 commit 失败数据不一致。

3. 三阶段提交

    canCommit -> preCommit  -> doCommit (client 的`超时`自动提交), 组后阶段的 abort ，client有可能收不到，导致数据的非一致性问题。

4. Paxos

    角色众多，提案者，接收者，learner.大多数。

    prepare -> promise

    accept -> accepted

5. raft 
    
    每个 节点有时间钟，heart beat成功则重置，到率先时间钟跑完的，变成 候选人，发出投票请求，其他的节点进行投票，票数占大多数的成为 leader.
    leader write -> precommit .大多数同意之后才能提交，否则无法提交成功，这样就解决了脑裂问题。

相比Paxos，Zab约束了事务顺序、适用于有强一致性需求的场景。

## Mysql

### 1. 事务

readuncommited -> 脏读 ，读取了别人未提交的

readcommited -> 不可重复读，两次读的过程中，被其他修改了

repeatableread -> 幻读，读的过程中新增了，或者删除。

seriableread

加锁，mvcc,multiversionconrrentctrol

### 锁

1. 读写锁 -> X锁（排他锁）,S锁（共享锁）。
2. 意向锁。一个事务获取 X,S锁之前先获取 意向锁。
1. 讨论加锁情况 需要 根据不同的事务隔离级别判断
2. innnoDB 一定存在 聚簇索引，默认主键作为 聚簇索引
3. 有几个索引，就有几棵B+树
4. 聚簇索引的叶子节点为磁盘上的真实数据。非聚簇索引的叶子节点除了保留值还指向聚簇索引。

5. S 共享锁 T2可读; X 排他锁 ；意向S锁，意向 X锁 ->对于表级锁请求检查
6. 加锁算法： 
    - RecordLocks : 行锁。 -> 索引记录 -> 最终落在 聚簇索引
    - Gap Locks: 间隙锁 -> RR Serializable 才有
    - Next-Key Locks: 行锁 + 间隙锁 
7. 快照读 当前读

    执行快照读，读的是 数据库的快照版本，是不加锁的。 -> 在 serial 中是一直加锁的。

8. RU/RC

    - 普通的都是 快照读不加锁
    - 最终落在 聚簇索引加 S，X锁
    - 对于 非聚簇索引 -》 会先在这个索引 + 聚簇索引加锁
9. RR/Serial

    - 需要多考虑间隙锁 -> 间隙锁就是锁 全表了
    - S,X 聚簇索引加 相应锁 ，还有间隙锁
    - = 等号的不加 间隙锁

### mvcc

创建版号 -> 创建时候系统版号
删除版号 -> 删除版号小于当前事务的版号，说明早就被删除了，所以只有大于时候有效。

开始一个事务时候，该事务的版本号 肯定大于 当前所有数据行快照创建的版本号。

undo 数据行所有的快照

把对一个个数据行没有修改的事务成为 T，T索要读取的数据行快照创建的版本号必须小于 T 的版本号。

使用 mvcc 是快照读，它不能解决 `幻读`的问题。

对于 快照读 mvcc解决，对于当前读，使用加锁。

当前读：

当前读，是读取最新的数据，需要加锁。

持久性通过redo log（重做日志）来实现，原子性和一致性通过Undo log来实现

B+树 ，所有叶子节点在同一层。-> 矮胖 -> 减少 磁盘 IO ->范围查询方便（直接在链表查询） -> 有顺序

索引是存储引擎层实现的

聚簇索引 非聚簇索引 Hash索引


B+树相比 红黑树，树的度不是2，会让树更矮，减少磁盘的IO,节点的顺序性，预读性质 -> 相邻节点能够载入。节点就是一页。

T1读--T2写（提交）--T1写--T1（幻读）这个顺序出现幻读。

# JVM

## 运行时 内存区域
1. 程序计数器 -> 恢复，循环，跳转 。no oom -> 字节码行号指示器
2. 虚拟机栈 -> 栈帧 -> 局部变量表 + 引用 -> stackoverflowerror,outofmemoryerror
3. 堆 -> TLAB ->GC -> JIT栈上分配
4. 方法区 -> 标准 永久代 -> metaspace ,类信息，常量，静态变量 ，即时编译的字节码
5. 运行时 常量池 -> 堆中 
6. 直接内存 -> NIO

## 对象的创建

1. 检查 类加载 -> 分配内存（在类加载完成之后确定）{1. 空闲列表2. 指针移动} -> 线程本地分配 -> CAS 失败重试 --> 初始化 0 -> 设置对象头
2. 对象头 -> hash,GC分代年龄，偏向锁，锁threadId等等。-> 类型指针   若是数组，对象头中还要记录长度
3. 访问方式 ： 句柄 -> 对象地址更改比较好，直接访问 -> 速度比较快
4. 堆溢出 -> 创建对象就好了 | 虚拟机栈ERROR -> 递归 | 方法区 ？ -> string.intern() 

## GC

1. GCRoot -> 1. 虚拟机栈中引用的对象， 方法区静态属性引用的，方法区常量引用的。
2. 软引用 -> 内存溢出钱 | 弱引用 -> 下一次垃圾回收之前 
3. finalize 拯救自己 -> 只会执行一次

无用的类 -> 所有实例被回收 classLoader被回收 所有引用都没有，避免反射

### 方法

1. 标记清除 -> 碎片 -> 空先列表 -> CMS conrrent marked sweep
2. 标记整理 - G1
3. 复制 -> 内存空间 -> 新生代

## GC 收集器

1. Serial 单线程 -> STW
2. ParNew -> Serial 的多线程版本 新生代 + CMS(老年代)
3. Parallel Scavenge 关注吞吐量
4. Serial Old /Parral Old
5. CMS 初始标记（STW）并发标记 ，重新标记 ，并发删除 ； `CPU 少的时候`，占用 比较多。CPU 多的时候无所谓。`浮动垃圾` -> 并发清除期间产生的垃圾 -> 导致 Full GC ->`碎片`
6. G1 -> 标记整理 -> 可预测的停顿 -> rememberset -> 避免全堆扫描 -> 分代收集 -> 区域概念 -> 优先回收价值区域 -> 化整为零 
7. G1 -> 初始标记 -> 并发标记 -> 最终标记（rememberset log + set） -> 筛选回收

## 对象分配策略

1. 对象优先 Eden -> Eden 不足 -> Minor GC
2. 大对象直接进入老年代 -> 虚拟机参数配置  -> 参数只对 serial parnew有效
3. age >15 可配置 --> s1 中所有 相同年龄的对象大小占 s 的一半。 -> 直接进入老年代
## 空间分配担保

1. MinorGC 前检查 老年代的最大可用连续空间是否大于全部的新生代所有对象的空间，如果可以没啥问题。不可以 -> 若允许失败->检查 是否大于 历次晋升到老年代的平均大小 -> 可以则 minorgC,不可以 Full

## 虚拟机工具
1. jps
2. jstat -gcutil pid 1000 20-----1 s 20次
3. jmap -dump vmid
4. jstack pid > pid.log -> ps -ef | grep java -> top pid top Hp 进程号 

## FullGC
1. system.gc
2. 老年代空间不足 -> 新生代的对象 转入 老年代 空间不足，尽量让 对象在 minorGC阶段被回收，让对象在新生代多生存一会
3. CMS GC 的时候 浮动垃圾 
4. 分配担保失败，在 minor GC的时候


# 算法

## 树相关

1. 根据前序遍历 中序遍历 构建二叉树 输出 后续遍历 

    思想： 前序遍历 的第一个节点 为 root节点，在中序遍历中找到 root的位置，中序遍历的前半部分的长度 为 左子树的size,右半部分为右子树的长度。可以将 pre 分割成 root_left_right .可以根据 数组
    分割递归的创建 left,right. 注意 中序遍历的 InL 左边界条件
2. 镜像 二叉树 。 swap -> root .然后递归调用 分别 root.left, root.right
3. 查找 一个节点的中序遍历下一个节点 - >如果有右孩子，那么由孩子`最左` 是下一个节点，如果没有右孩子，则该节点的 `父节点`为下一个节点
4.  链表的反转 需要记住
```java
class Solution {
    public ListNode reverseList(ListNode head) {
        if (head == null || head.next == null) {
            return head;
        }
        ListNode next = head.next;
        ListNode newHead = reverseList(next); // 找到最后一个
        next.next = head;
        head.next = null;
        return newHead;
    }
}

```

5. 链表中删除重复的节点有点晕啊


使用递归来解决该题，主要就是递归的三部曲：

找终止条件：本题终止条件很明显，当递归到链表为空或者链表只剩一个元素的时候，没得交换了，自然就终止了。
找返回值：返回给上一层递归的值应该是已经交换完成后的子链表。
单次的过程：因为递归是重复做一样的事情，所以从宏观上考虑，只用考虑某一步是怎么完成的。我们假设待交换的俩节点分别为head和next，next的应该接受上一级返回的子链表(参考第2步)。就相当于是一个含三个节点的链表交换前两个节点，就很简单了，想不明白的画画图就ok。

## linux
1. select -> fdset(bitmap) -> 从 用户态 copy 到内核态 - > 没有数据的时候select阻塞，有数据返回，用户态判断 -> 开始读取数据
    缺点：
    bitmap -> 1024 上限 -> fdset不可重用 ，copy过程开销（用户态 到内核态），返回的时候还需要遍历看哪个有数据

2. epoll -> fd_events - > 不用copy 共享内存 ->  有数据 （重排）-> 返回值 

## 需要复习的部分

1. spring 看博客 bean
2. select,poll,epoll
3. 


## RocketMQ
1. NameServer 元数据管理 类似 zk,主要维持心跳 提供 topic broker的关系，broker -> nameServer 发送消息时候带上 topic
    nameserver 无状态，集群内部之间不通讯
2. Producer -> 负载均衡发送到 Broker
3. Broker 与 nameServer 维持心跳连接，是 mq 的服务器，负责存储。
4. Consumer push -> 注册监听器
5. topic tag group

producer 在 nameServer 注册服务. 与 broker master 建立连接

consumer master,slavel两个连接。

## LevelDB

1. LevelDB 的内部已经内置了内存缓存和持久层的磁盘文件，用户完全不用操心内部是数据如何保持一致的。
2. 在使用 LevelDB时候，可以看作一个 Key/Value 内存数据库


## netty

BIO 读写等待阻塞，浪费 线程，基于 stream 

NIO Reactor模型，基于 channel buffer 

内存映射：为了提高大文件的读写速度。 FileChannel 和 MappedByteBuffer

事件驱动的IO多路复用模型

Decoder Encoder

handler回调 不用判断 降低了NIO的复杂度

TCP粘包拆包问题，支持TCP UDP,心跳

## JUC

1. CountDownLatch 与 CyclicBarrier 前者 只能使用一次，前者 countdown不阻塞。后者相当于等所有的线程到达才继续执行。


## zookeeper

1. 配置 监听节点 更新配置
2. 负载均衡 统一命名服务
3. 服务器的动态上下线
4. get /shandong/xxx watch .注册监听，只能注册一次。
5. create /shandong/jinan "jinan"
6. 服务器注册 临时节点 。客户端监听节点。服务器的上线 下线 都会被客户端监听到。再次注册监听。
7. 持久性 节点 短暂的节点
8. 节点的结构体
9. connect 线程 与 listen 线程。 connect 负责 建立连接，注册监听 ，zk 将变化发送给 listen 
10. 选举机制
    半数以上， 奇数。leader,flower.leader与启动顺序也有一定的关系。超过半数以上。

11. 写操作 -> 转发给leader -> leader 广播给各个server,进入待写队列 ，并向leader发送成功信息，一半以上的代表成功，返回client 成功。
12. 分布式领域中，在当前情况下，是不可能存在强一致性的。
   强一致性，弱一致性，最终一致性。

   最终一致性：允许短暂数据读取的不一致


