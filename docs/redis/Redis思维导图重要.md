
<!-- TOC -->

- [基础](#基础)
- [分布式锁](#分布式锁)
- [延时队列](#延时队列)
- [位图](#位图)
- [HyperLoglog(重点了解一下)](#hyperloglog重点了解一下)
- [BloomFilter](#bloomfilter)
- [限流](#限流)
- [GeoHash 地图](#geohash-地图)
- [scan（重点）](#scan重点)
- [IO模型](#io模型)
- [通信协议](#通信协议)
- [持久化](#持久化)
- [管道](#管道)
- [事务](#事务)
- [PubSub 发布订阅模式（这个已经淘汰了，使用 stream）](#pubsub-发布订阅模式这个已经淘汰了使用-stream)
- [Stream](#stream)
- [小对象压缩](#小对象压缩)
- [内存回收问题](#内存回收问题)
- [主从同步](#主从同步)
- [sentinel](#sentinel)
- [Cluster](#cluster)
- [Info](#info)
- [过期策略](#过期策略)
- [Jedis](#jedis)
- [其他](#其他)
- [数据结构](#数据结构)

<!-- /TOC -->

## 基础
1. 5+ 种数据结构 list set zset hash string
2. key 都是字符串，value是不同的数据结构，SDS,1M,>1M,预分配，懒回收
3. expire 过期的是数据结构，并不能是单个的key
4. list -> linkedlist -> get效率低，可以当作队列和栈使用
5. ziplist 压缩列表，因为 结构有冗余的前后指针
6. hash.数组链表 ，rehash.慢慢来。
7. set 可以用来去重。粉丝列表。zset,抽奖
8. zset 跳跃表 ，logn ，二分法，随机分层，学生成绩，粉丝关注

## 分布式锁

1. set nx expire time , 过期时间，value 随机，删除lua 判断。避免长时间的占用
2. 原子操作，clientA读取 ，操作 ，set.BClient同样操作，需要加锁。
3. 最好是不要可重入,增加复杂度
4. redlock
5. 主从节点同步的时候，在主节点获得一把锁，然后主节点挂掉，没有同步从，就会被别人重新拿到锁
6. Redlock 向过半的节点发送这个指令，只有过半的成功，才算成功，效率不太高


## 延时队列

1. list -> rpush/lpush -> lpop/rpop 异步消息队列
2. 队列空了。sleep pop会死循环。浪费，空轮询。blpop,brpop.阻塞读。当数据没有的时候，休眠
3. 分布式锁加锁失败的时候 放入到延迟队列中。
4. 延迟队列是使用的 zset(重点)
5. stream 发布订阅模式

## 位图
1. bitmap 签到记录，登录记录。做运算
2. bitpos bitcount 统计作用

## HyperLoglog(重点了解一下)

1. 统计大数据量的 PV,UV，UV需要去重，不能使用 set吧
2. pfadd,pfcount，pfmerge
3. 可以用来统计全局的数据，占用12K

## BloomFilter

1. 历史消息，不同的hash算法。爬虫 URL 去重
2. redis 4.0 才上的
3. 存在一定会存在，不存在有可能有可能显示存在
4. Google BloomFilter 有jar,可以设置比率

## 限流
1.  漏斗算法 -> 不能应对突发流量 令牌桶算法-> 可以应对突发 固定时间窗口-> 中间问题 动态时间窗口 -> 复杂不好空寂
2. 这块不重要

## GeoHash 地图 
1. 整成一维整数，一条线

## scan（重点）
1. keys不行，单线程，卡顿。scan 可控，不卡顿
2. 游标，不会阻塞线程。
3. limit,可以匹配
4. 客户端需要去重
5. 游标的算法比较复杂

## IO模型

1. IO多路复用
2. 连接应答处理器 命令请求处理器 命令回复处理器
3. AE_Readable 监听这个事件，发生，-> 连接应答处理器 -> 监听与客户端的socket.read，事件
4. 可读可写不会阻塞，事件通知相应的handler
5. 连接应答处理器，命令请求处理器，命令回复处理器


## 通信协议

1. 文本通信，特殊字符分割
2. 基于内存，本身就很快。瓶颈在IO,不在网络通信

## 持久化
1. RDB -> fork子进程 Copy On Write-> 缓存指令 -> 内存二进制压缩 -> 备份 -> 主从同步
2. AOF -> 指令集合 -> 重写 -> 占用大 -> 重放 -> 数据丢失比较少可以设置1s存盘一次
3. 混合持久化 4.0

## 管道
1. 指令集 避免来回的网络延迟
2. 合并了多条 pipline 与事务混合使用
## 事务
1. 不严格 
2. 与管道配置使用
3. watch 指令，盯住某个key.发生变化重试

## PubSub 发布订阅模式（这个已经淘汰了，使用 stream）
1. 新的数据类型
2. 都有线程的接口 根据topic 订阅 和 发布

## Stream
1. 消息队列
2. 太复杂，不想看

## 小对象压缩
1. 32bit vs 64 bit
2. ziplist 数据量少，冗余的结构浪费空间，压缩在一起
3. 存储上限达到 -> 正常的数据结构
4. 里面存储了len.大小等信息，便于分割

## 内存回收问题
1. 引用计数法
2. 无用的key占用的内存不一定被回收，整个页全部无用key才会被回收，key的位置可以宠用

## 主从同步
1. CAP -> 分布式 网络分区不可避免，想要 强一致性，就得停机不可用。可用就得非一致性
2. 主从同步 -> 快照同步 -> 环形数组 -> 增量同步 偏移量 -> 避免死循环
3. 遍历 ->socket -> 避免了IO
4. wait 指令，必须同步N个节点的时候才返回 ，sentinel也有类似功能

## sentinel
1. 集群 监控 主从节点健康（zk集群）
2. client 请求 sentinel 返回 主节点的地址
3. 切换主从，可能会丢失部分数据，当然可以通过配置 调整必须同步成功才返回成功
4. 在连接的时候会比对更新

## Cluster
1. 集群管理 分片处理
2. 相当于中间件。集群。slot 集群的管理不同的槽位
3. redis cluster 发送数据的时候 会查到 配置信息，直接定位目标节点
4. 如果目标节点错了，会给他重定向，并且告诉它的正确节点，客户端更新
5. 自动迁移，自动负载均衡 -> 迁移单位 slot -> 会阻塞

## Info
1. info memory 查看内存占用情况
2. info stats | grep ops // 查看每秒的请求
3. info clients 查看连接 的客户端数量

## 过期策略
1. expire 都有一个过期 的集合
2. 定时扫描 ，随机选择 -> 避免数据量太大，CPU压力过大
3. 惰性删除
5. 存储的时候，加载的时候过滤掉
6. LRU 最近最少使用的
7. LRU -> Map + LinkedList 头节点，移除尾节点
7. 从节点不会主动删除，被动删除

## Jedis
1. try-with-resorece 语法糖 便于关闭 连接

## 其他
1. rename keys,fulushDB等命令，避免使用

## 数据结构
1. string -> SDS -> free,len -> 预分配 懒回收 -> 1M
2. hash -> 字典链表 -> rehash
3. ziplist,skiplist